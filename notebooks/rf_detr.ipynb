{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import yaml\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "def yolo_to_coco(dataset_path, output_path):\n",
        "    dataset_path = Path(dataset_path)\n",
        "    output_path = Path(output_path)\n",
        "    output_path.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    with open(dataset_path / 'data.yaml', 'r') as f:\n",
        "        data_config = yaml.safe_load(f)\n",
        "    \n",
        "    categories = [\n",
        "        {'id': i, 'name': name, 'supercategory': 'object'} \n",
        "        for i, name in enumerate(data_config['names'])\n",
        "    ]\n",
        "    \n",
        "    splits = ['train', 'valid', 'test']\n",
        "    \n",
        "    for split in splits:\n",
        "        print(f\"\\nProcessing {split} split...\")\n",
        "        \n",
        "        images_dir = dataset_path / 'images' / split\n",
        "        labels_dir = dataset_path / 'labels' / split\n",
        "        \n",
        "        if not images_dir.exists():\n",
        "            print(f\"Skipping {split} - directory not found\")\n",
        "            continue\n",
        "        \n",
        "        split_output_dir = output_path / split\n",
        "        split_output_dir.mkdir(parents=True, exist_ok=True)\n",
        "        \n",
        "        coco_data = {\n",
        "            'images': [],\n",
        "            'annotations': [],\n",
        "            'categories': categories\n",
        "        }\n",
        "        \n",
        "        image_id = 0\n",
        "        annotation_id = 0\n",
        "        \n",
        "        image_files = sorted(list(images_dir.glob('*.jpg')) + list(images_dir.glob('*.png')))\n",
        "        \n",
        "        for img_path in tqdm(image_files, desc=f\"Converting {split}\"):\n",
        "            try:\n",
        "                img = Image.open(img_path)\n",
        "                width, height = img.size\n",
        "                \n",
        "                coco_data['images'].append({\n",
        "                    'id': image_id,\n",
        "                    'file_name': img_path.name,\n",
        "                    'width': width,\n",
        "                    'height': height\n",
        "                })\n",
        "                \n",
        "                label_path = labels_dir / f\"{img_path.stem}.txt\"\n",
        "                \n",
        "                if label_path.exists():\n",
        "                    with open(label_path, 'r') as f:\n",
        "                        lines = f.readlines()\n",
        "                    \n",
        "                    for line in lines:\n",
        "                        parts = line.strip().split()\n",
        "                        if len(parts) >= 5:\n",
        "                            class_id = int(parts[0])\n",
        "                            x_center = float(parts[1])\n",
        "                            y_center = float(parts[2])\n",
        "                            w = float(parts[3])\n",
        "                            h = float(parts[4])\n",
        "                            \n",
        "                            x_min = (x_center - w / 2) * width\n",
        "                            y_min = (y_center - h / 2) * height\n",
        "                            bbox_width = w * width\n",
        "                            bbox_height = h * height\n",
        "                            \n",
        "                            coco_data['annotations'].append({\n",
        "                                'id': annotation_id,\n",
        "                                'image_id': image_id,\n",
        "                                'category_id': class_id,\n",
        "                                'bbox': [x_min, y_min, bbox_width, bbox_height],\n",
        "                                'area': bbox_width * bbox_height,\n",
        "                                'iscrowd': 0\n",
        "                            })\n",
        "                            annotation_id += 1\n",
        "                \n",
        "                image_id += 1\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {img_path}: {e}\")\n",
        "                continue\n",
        "        \n",
        "        output_file = split_output_dir / \"_annotations.coco.json\"\n",
        "        with open(output_file, 'w') as f:\n",
        "            json.dump(coco_data, f, indent=2)\n",
        "        \n",
        "        print(f\"Saved {split}: {len(coco_data['images'])} images, {len(coco_data['annotations'])} annotations\")\n",
        "        print(f\"Output: {output_file}\")\n",
        "\n",
        "dataset_path = '/workspace/yolo_dataset_4_dec'\n",
        "output_path = '/workspace/coco_dataset'\n",
        "\n",
        "yolo_to_coco(dataset_path, output_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"Copying images to COCO dataset structure...\")\n",
        "\n",
        "source_path = Path('/workspace/yolo_dataset_4_dec')\n",
        "dest_path = Path('/workspace/coco_dataset')\n",
        "\n",
        "for split in ['train', 'valid', 'test']:\n",
        "    source_images = source_path / 'images' / split\n",
        "    dest_images = dest_path / split\n",
        "    \n",
        "    if source_images.exists():\n",
        "        dest_images.mkdir(parents=True, exist_ok=True)\n",
        "        print(f\"\\nCopying {split} images...\")\n",
        "        \n",
        "        for img_file in source_images.glob('*'):\n",
        "            if img_file.suffix.lower() in ['.jpg', '.jpeg', '.png']:\n",
        "                shutil.copy2(img_file, dest_images / img_file.name)\n",
        "        \n",
        "        image_count = len([f for f in dest_images.glob('*') if f.suffix.lower() in ['.jpg', '.jpeg', '.png']])\n",
        "        print(f\"Copied {image_count} {split} images\")\n",
        "\n",
        "print(\"\\nCOCO dataset structure ready!\")\n",
        "print(f\"Dataset location: {dest_path}\")\n",
        "print(\"\\nExpected structure:\")\n",
        "print(\"coco_dataset/\")\n",
        "print(\"├── train/\")\n",
        "print(\"│   ├── image1.jpg\")\n",
        "print(\"│   ├── image2.jpg\")\n",
        "print(\"│   └── _annotations.coco.json\")\n",
        "print(\"├── valid/\")\n",
        "print(\"│   ├── image1.jpg\")\n",
        "print(\"│   └── _annotations.coco.json\")\n",
        "print(\"└── test/\")\n",
        "print(\"    ├── image1.jpg\")\n",
        "print(\"    └── _annotations.coco.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train RF-DETR Model\n",
        "\n",
        "Training configuration:\n",
        "- **Classes**: 4 (knife, gun, rifle, baseball_bat)\n",
        "- **Backbone**: ResNet50\n",
        "- **Epochs**: 50\n",
        "- **Batch Size**: 4 (adjust based on GPU memory)\n",
        "- **Learning Rate**: 1e-4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train RF-DETR Using Python API\n",
        "\n",
        "Using the RFDETRBase class with callbacks to track training progress."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from rfdetr import RFDETRBase\n",
        "\n",
        "model = RFDETRBase()\n",
        "history = []\n",
        "\n",
        "def callback2(data):\n",
        "    history.append(data)\n",
        "\n",
        "model.callbacks[\"on_fit_epoch_end\"].append(callback2)\n",
        "\n",
        "model.train(\n",
        "    dataset_dir=\"/workspace/coco_dataset\",\n",
        "    epochs=50,\n",
        "    batch_size=16,\n",
        "    lr=1e-4\n",
        ")\n",
        "\n",
        "print(\"\\nTraining completed!\")\n",
        "print(f\"Total epochs: {len(history)}\")\n",
        "\n",
        "for epoch_data in history[-5:]:\n",
        "    print(f\"Epoch {epoch_data.get('epoch', 'N/A')}: Loss = {epoch_data.get('loss', 'N/A')}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
