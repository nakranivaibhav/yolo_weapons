{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "951bdd83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (17411, 1024)\n",
      "Total images: 17411\n",
      "Example path: /workspace/yolo_dataset_4_dec/images/test/cellphone_test_002379.png\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import shutil\n",
    "\n",
    "data = np.load(\"/workspace/yolo_dangerous_weapons/embeddings.npz\", allow_pickle=True)\n",
    "\n",
    "embeddings = data['embeddings']\n",
    "paths = data['paths']\n",
    "labels = data['labels']\n",
    "splits = data['splits']\n",
    "\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "print(f\"Total images: {len(paths)}\")\n",
    "print(f\"Example path: {paths[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6df21b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18 problematic images:\n",
      "  - voc_train_005576.jpg\n",
      "  - voc_train_007141.jpg\n",
      "  - voc_valid_001682.jpg\n",
      "  - voc_train_007968.jpg\n",
      "  - voc_valid_000964.jpg\n"
     ]
    }
   ],
   "source": [
    "problematic_md = Path(\"/workspace/yolo_dangerous_weapons/outliers/problematic.md\")\n",
    "\n",
    "problematic_images = []\n",
    "with open(problematic_md, 'r') as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if line and not line.startswith('#'):\n",
    "            problematic_images.append(line)\n",
    "\n",
    "print(f\"Found {len(problematic_images)} problematic images:\")\n",
    "for img in problematic_images[:5]:\n",
    "    print(f\"  - {img}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4688269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created path index with 17411 entries\n",
      "Example: cellphone_test_002379.png\n"
     ]
    }
   ],
   "source": [
    "def extract_image_name(path_str):\n",
    "    \"\"\"Extract image name from full path.\"\"\"\n",
    "    return Path(path_str).name\n",
    "\n",
    "path_to_idx = {extract_image_name(p): i for i, p in enumerate(paths)}\n",
    "\n",
    "print(f\"Created path index with {len(path_to_idx)} entries\")\n",
    "print(f\"Example: {list(path_to_idx.keys())[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2d59ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Top 5 similar to /workspace/yolo_dataset_4_dec/images/test/cellphone_test_002379.png:\n",
      "  0.9951 - cellphone_train_013499.png\n",
      "  0.9698 - cellphone_train_013222.png\n",
      "  0.9650 - cellphone_train_013161.png\n",
      "  0.9594 - cellphone_train_013263.png\n",
      "  0.9576 - cellphone_valid_002718.png\n"
     ]
    }
   ],
   "source": [
    "def find_top_similar(query_idx, embeddings, top_k=20):\n",
    "    \"\"\"Find top K most similar images to query image.\"\"\"\n",
    "    query_emb = embeddings[query_idx].reshape(1, -1)\n",
    "    similarities = cosine_similarity(query_emb, embeddings)[0]\n",
    "    \n",
    "    similar_indices = np.argsort(similarities)[::-1]\n",
    "    similar_indices = similar_indices[similar_indices != query_idx][:top_k]\n",
    "    \n",
    "    results = []\n",
    "    for idx in similar_indices:\n",
    "        results.append({\n",
    "            'idx': idx,\n",
    "            'path': paths[idx],\n",
    "            'similarity': similarities[idx],\n",
    "            'label': labels[idx],\n",
    "            'split': splits[idx]\n",
    "        })\n",
    "    return results\n",
    "\n",
    "test_idx = 0\n",
    "test_results = find_top_similar(test_idx, embeddings, top_k=5)\n",
    "print(f\"Test: Top 5 similar to {paths[test_idx]}:\")\n",
    "for r in test_results:\n",
    "    print(f\"  {r['similarity']:.4f} - {Path(r['path']).name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8741c4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20 similar images for voc_train_005576.jpg\n",
      "Found 20 similar images for voc_train_007141.jpg\n",
      "Found 20 similar images for voc_valid_001682.jpg\n",
      "Found 20 similar images for voc_train_007968.jpg\n",
      "Found 20 similar images for voc_valid_000964.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20 similar images for youtube_train_008637.jpg\n",
      "Found 20 similar images for dangerous_train_004347.jpg\n",
      "Found 20 similar images for voc_train_007874.jpg\n",
      "Found 20 similar images for crowdhuman_train_012069.jpg\n",
      "Found 20 similar images for voc_train_007896.jpg\n",
      "Found 20 similar images for voc_train_004498.jpg\n",
      "Found 20 similar images for voc_train_005823.jpg\n",
      "Found 20 similar images for voc_valid_000978.jpg\n",
      "Found 20 similar images for voc_test_001110.jpg\n",
      "Found 20 similar images for voc_train_005801.jpg\n",
      "Found 20 similar images for voc_train_008012.jpg\n",
      "Found 20 similar images for voc_train_006651.jpg\n",
      "Found 20 similar images for voc_test_001499.jpg\n",
      "\n",
      "Processed: 18 images\n",
      "Not found: 0 images\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_BASE = Path(\"/workspace/problematic_similar_images\")\n",
    "if OUTPUT_BASE.exists():\n",
    "    shutil.rmtree(OUTPUT_BASE)\n",
    "OUTPUT_BASE.mkdir(parents=True)\n",
    "\n",
    "all_results = {}\n",
    "not_found = []\n",
    "\n",
    "for prob_img in problematic_images:\n",
    "    if prob_img in path_to_idx:\n",
    "        idx = path_to_idx[prob_img]\n",
    "        similar = find_top_similar(idx, embeddings, top_k=20)\n",
    "        all_results[prob_img] = similar\n",
    "        print(f\"Found {len(similar)} similar images for {prob_img}\")\n",
    "    else:\n",
    "        not_found.append(prob_img)\n",
    "        print(f\"NOT FOUND: {prob_img}\")\n",
    "\n",
    "print(f\"\\nProcessed: {len(all_results)} images\")\n",
    "print(f\"Not found: {len(not_found)} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4de14f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied 378 images\n",
      "Missing 0 images\n",
      "Created 18 folders in /workspace/problematic_similar_images\n"
     ]
    }
   ],
   "source": [
    "yolo_dataset = Path(\"/workspace/yolo_dataset_4_dec\")\n",
    "copied_count = 0\n",
    "missing_count = 0\n",
    "\n",
    "for prob_img, similar_list in all_results.items():\n",
    "    prob_name = Path(prob_img).stem\n",
    "    folder = OUTPUT_BASE / prob_name\n",
    "    folder.mkdir(exist_ok=True)\n",
    "    \n",
    "    prob_idx = path_to_idx[prob_img]\n",
    "    prob_source = Path(paths[prob_idx])\n",
    "    if prob_source.exists():\n",
    "        shutil.copy2(prob_source, folder / f\"000_QUERY_{prob_img}\")\n",
    "        copied_count += 1\n",
    "    \n",
    "    for i, sim_item in enumerate(similar_list, 1):\n",
    "        source_path = Path(sim_item['path'])\n",
    "        if source_path.exists():\n",
    "            sim_score = sim_item['similarity']\n",
    "            dest_name = f\"{i:03d}_sim{sim_score:.3f}_{source_path.name}\"\n",
    "            shutil.copy2(source_path, folder / dest_name)\n",
    "            copied_count += 1\n",
    "        else:\n",
    "            missing_count += 1\n",
    "\n",
    "print(f\"Copied {copied_count} images\")\n",
    "print(f\"Missing {missing_count} images\")\n",
    "print(f\"Created {len(all_results)} folders in {OUTPUT_BASE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72ebde4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SUMMARY\n",
      "============================================================\n",
      "\n",
      "Output directory: /workspace/problematic_similar_images\n",
      "\n",
      "Processed 18 problematic images\n",
      "  - Found in embeddings: 18\n",
      "  - Not found: 0\n",
      "\n",
      "For each problematic image:\n",
      "  - Created folder with image stem name\n",
      "  - Copied query image as 000_QUERY_*\n",
      "  - Copied top 20 similar images as 001_sim*.jpg, 002_sim*.jpg, etc.\n",
      "\n",
      "Folder structure:\n",
      "  /workspace/problematic_similar_images/voc_train_005576/\n",
      "    - 000_QUERY_voc_train_005576.jpg\n",
      "    - 001_sim*.jpg to 020_sim*.jpg\n",
      "  /workspace/problematic_similar_images/voc_train_007141/\n",
      "    - 000_QUERY_voc_train_007141.jpg\n",
      "    - 001_sim*.jpg to 020_sim*.jpg\n",
      "  /workspace/problematic_similar_images/voc_valid_001682/\n",
      "    - 000_QUERY_voc_valid_001682.jpg\n",
      "    - 001_sim*.jpg to 020_sim*.jpg\n",
      "  ...\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nOutput directory: {OUTPUT_BASE}\")\n",
    "print(f\"\\nProcessed {len(problematic_images)} problematic images\")\n",
    "print(f\"  - Found in embeddings: {len(all_results)}\")\n",
    "print(f\"  - Not found: {len(not_found)}\")\n",
    "\n",
    "print(f\"\\nFor each problematic image:\")\n",
    "print(f\"  - Created folder with image stem name\")\n",
    "print(f\"  - Copied query image as 000_QUERY_*\")\n",
    "print(f\"  - Copied top 20 similar images as 001_sim*.jpg, 002_sim*.jpg, etc.\")\n",
    "\n",
    "print(f\"\\nFolder structure:\")\n",
    "for prob_img in list(all_results.keys())[:3]:\n",
    "    folder_name = Path(prob_img).stem\n",
    "    print(f\"  {OUTPUT_BASE / folder_name}/\")\n",
    "    print(f\"    - 000_QUERY_{prob_img}\")\n",
    "    print(f\"    - 001_sim*.jpg to 020_sim*.jpg\")\n",
    "print(\"  ...\")\n",
    "\n",
    "if not_found:\n",
    "    print(f\"\\nNot found in embeddings:\")\n",
    "    for img in not_found:\n",
    "        print(f\"  - {img}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c3e3bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity statistics:\n",
      "  Mean similarity: 0.9351\n",
      "  Min similarity: 0.9012\n",
      "  Max similarity: 0.9767\n",
      "\n",
      "Label distribution of similar images:\n",
      "label\n",
      "train    256\n",
      "valid     54\n",
      "test      50\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Saved detailed results to: /workspace/problematic_similar_images/similarity_results.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "similarity_stats = []\n",
    "for prob_img, similar_list in all_results.items():\n",
    "    for sim_item in similar_list:\n",
    "        similarity_stats.append({\n",
    "            'query': prob_img,\n",
    "            'similar': Path(sim_item['path']).name,\n",
    "            'similarity': sim_item['similarity'],\n",
    "            'label': sim_item['label'],\n",
    "            'split': sim_item['split']\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(similarity_stats)\n",
    "print(f\"\\nSimilarity statistics:\")\n",
    "print(f\"  Mean similarity: {df['similarity'].mean():.4f}\")\n",
    "print(f\"  Min similarity: {df['similarity'].min():.4f}\")\n",
    "print(f\"  Max similarity: {df['similarity'].max():.4f}\")\n",
    "print(f\"\\nLabel distribution of similar images:\")\n",
    "print(df['label'].value_counts())\n",
    "\n",
    "csv_path = OUTPUT_BASE / \"similarity_results.csv\"\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f\"\\nSaved detailed results to: {csv_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
