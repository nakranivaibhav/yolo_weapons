{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f36a4601",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from cleanlab.count import compute_confident_joint\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "PREDICTIONS_PATH = Path(\"/workspace/cv_folds_5fold/predictions\")\n",
        "CLASS_NAMES = ['knife', 'gun', 'rifle', 'baseball_bat', 'background']\n",
        "NUM_CLASSES = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16d30fb1",
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(PREDICTIONS_PATH / \"all_predictions.pkl\", \"rb\") as f:\n",
        "    all_predictions = pickle.load(f)\n",
        "\n",
        "print(f\"Total images: {len(all_predictions)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2e6d3a8",
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_primary_class(gt_boxes):\n",
        "    if not gt_boxes:\n",
        "        return 4\n",
        "    classes = [b['class_id'] for b in gt_boxes]\n",
        "    return max(set(classes), key=classes.count)\n",
        "\n",
        "def get_pred_probs(pred_boxes, num_classes=5):\n",
        "    probs = np.zeros(num_classes)\n",
        "    if not pred_boxes:\n",
        "        probs[4] = 1.0\n",
        "        return probs\n",
        "    for box in pred_boxes:\n",
        "        cls_id = box['class_id']\n",
        "        conf = box['confidence']\n",
        "        probs[cls_id] = max(probs[cls_id], conf)\n",
        "    if probs[:4].sum() == 0:\n",
        "        probs[4] = 1.0\n",
        "    else:\n",
        "        probs[4] = max(0, 1.0 - probs[:4].max())\n",
        "    probs = probs / probs.sum()\n",
        "    return probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4aed78fc",
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = []\n",
        "pred_probs = []\n",
        "image_paths = []\n",
        "\n",
        "for img_path, data in all_predictions.items():\n",
        "    label = get_primary_class(data['ground_truth'])\n",
        "    probs = get_pred_probs(data['predictions'], NUM_CLASSES)\n",
        "    labels.append(label)\n",
        "    pred_probs.append(probs)\n",
        "    image_paths.append(img_path)\n",
        "\n",
        "labels = np.array(labels)\n",
        "pred_probs = np.array(pred_probs)\n",
        "\n",
        "print(f\"Labels shape: {labels.shape}\")\n",
        "print(f\"Pred probs shape: {pred_probs.shape}\")\n",
        "print(f\"\\nLabel distribution:\")\n",
        "for i, name in enumerate(CLASS_NAMES):\n",
        "    print(f\"  {name}: {(labels == i).sum()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70696a9a",
      "metadata": {},
      "outputs": [],
      "source": [
        "confident_joint, off_diag_indices = compute_confident_joint(\n",
        "    labels=labels,\n",
        "    pred_probs=pred_probs,\n",
        "    calibrate=True,\n",
        "    return_indices_of_off_diagonals=True\n",
        ")\n",
        "\n",
        "print(\"Confident Joint Matrix:\")\n",
        "print(confident_joint)\n",
        "print(f\"\\nOff-diagonal examples (potential label errors): {len(off_diag_indices)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77824ce9",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(\n",
        "    confident_joint,\n",
        "    annot=True,\n",
        "    fmt='d',\n",
        "    cmap='Blues',\n",
        "    xticklabels=CLASS_NAMES,\n",
        "    yticklabels=CLASS_NAMES\n",
        ")\n",
        "plt.xlabel('Predicted Class')\n",
        "plt.ylabel('Given Label')\n",
        "plt.title('Confident Joint Matrix')\n",
        "plt.tight_layout()\n",
        "plt.savefig(PREDICTIONS_PATH / 'confident_joint.png', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed0a4132",
      "metadata": {},
      "outputs": [],
      "source": [
        "error_candidates = []\n",
        "for idx in off_diag_indices:\n",
        "    given_label = labels[idx]\n",
        "    pred_label = np.argmax(pred_probs[idx])\n",
        "    pred_conf = pred_probs[idx][pred_label]\n",
        "    error_candidates.append({\n",
        "        'image_path': image_paths[idx],\n",
        "        'given_label': CLASS_NAMES[given_label],\n",
        "        'predicted_label': CLASS_NAMES[pred_label],\n",
        "        'predicted_conf': pred_conf,\n",
        "        'given_label_id': given_label,\n",
        "        'predicted_label_id': pred_label\n",
        "    })\n",
        "\n",
        "errors_df = pd.DataFrame(error_candidates)\n",
        "errors_df = errors_df.sort_values('predicted_conf', ascending=False)\n",
        "print(f\"Total potential label errors: {len(errors_df)}\")\n",
        "errors_df.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e92b191",
      "metadata": {},
      "outputs": [],
      "source": [
        "errors_df.to_csv(PREDICTIONS_PATH / 'label_errors.csv', index=False)\n",
        "np.save(PREDICTIONS_PATH / 'confident_joint.npy', confident_joint)\n",
        "\n",
        "print(f\"Saved: {PREDICTIONS_PATH / 'label_errors.csv'}\")\n",
        "print(f\"Saved: {PREDICTIONS_PATH / 'confident_joint.npy'}\")\n",
        "\n",
        "print(\"\\nError breakdown by type:\")\n",
        "print(errors_df.groupby(['given_label', 'predicted_label']).size().sort_values(ascending=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc42fa88",
      "metadata": {},
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "INSPECTION_PATH = Path(\"/workspace/cv_folds_5fold/label_errors_inspection\")\n",
        "if INSPECTION_PATH.exists():\n",
        "    shutil.rmtree(INSPECTION_PATH)\n",
        "INSPECTION_PATH.mkdir(parents=True)\n",
        "\n",
        "for _, row in errors_df.iterrows():\n",
        "    img_path = Path(row['image_path'])\n",
        "    folder_name = f\"labeled_{row['given_label']}_pred_{row['predicted_label']}\"\n",
        "    folder = INSPECTION_PATH / folder_name\n",
        "    folder.mkdir(exist_ok=True)\n",
        "    \n",
        "    label_path = img_path.parent.parent / 'labels' / 'val' / f\"{img_path.stem}.txt\"\n",
        "    \n",
        "    shutil.copy2(img_path, folder / img_path.name)\n",
        "    if label_path.exists():\n",
        "        shutil.copy2(label_path, folder / label_path.name)\n",
        "\n",
        "print(f\"Organized {len(errors_df)} images into: {INSPECTION_PATH}\")\n",
        "for folder in sorted(INSPECTION_PATH.iterdir()):\n",
        "    count = len(list(folder.glob('*.jpg'))) + len(list(folder.glob('*.png')))\n",
        "    print(f\"  {folder.name}: {count} images\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
